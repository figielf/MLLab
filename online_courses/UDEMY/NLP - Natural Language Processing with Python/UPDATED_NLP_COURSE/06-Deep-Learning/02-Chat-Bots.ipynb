{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___\n",
    "# Question and Answer Chat Bots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Data\n",
    "\n",
    "We will be working with the Babi Data Set from Facebook Research.\n",
    "\n",
    "Full Details: https://research.fb.com/downloads/babi/\n",
    "\n",
    "- Jason Weston, Antoine Bordes, Sumit Chopra, Tomas Mikolov, Alexander M. Rush,\n",
    "  \"Towards AI-Complete Question Answering: A Set of Prerequisite Toy Tasks\",\n",
    "  http://arxiv.org/abs/1502.05698\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    train_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_qa.txt\", \"rb\") as fp:   # Unpickling\n",
    "    test_data =  pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Format of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Mary',\n",
       "  'moved',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bathroom',\n",
       "  '.',\n",
       "  'Sandra',\n",
       "  'journeyed',\n",
       "  'to',\n",
       "  'the',\n",
       "  'bedroom',\n",
       "  '.'],\n",
       " ['Is', 'Sandra', 'in', 'the', 'hallway', '?'],\n",
       " 'no')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "## Setting up Vocabulary of All Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set that holds the vocab words\n",
    "vocab = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story, question , answer in all_data:\n",
    "    # In case you don't know what a union of sets is:\n",
    "    # https://www.programiz.com/python-programming/methods/set/union\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_len = len(vocab) + 1 #we add an extra space to hold a 0 for Keras's pad_sequences\n",
    "vocab_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = max([len(data[0]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_story_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reserve 0 for pad_sequences\n",
    "vocab_size = len(vocab) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# integer encode sequences of words\n",
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.': 13,\n",
       " '?': 12,\n",
       " 'apple': 3,\n",
       " 'back': 18,\n",
       " 'bathroom': 23,\n",
       " 'bedroom': 29,\n",
       " 'daniel': 21,\n",
       " 'discarded': 5,\n",
       " 'down': 22,\n",
       " 'dropped': 4,\n",
       " 'football': 37,\n",
       " 'garden': 36,\n",
       " 'got': 34,\n",
       " 'grabbed': 15,\n",
       " 'hallway': 27,\n",
       " 'in': 8,\n",
       " 'is': 30,\n",
       " 'john': 10,\n",
       " 'journeyed': 35,\n",
       " 'kitchen': 11,\n",
       " 'left': 31,\n",
       " 'mary': 25,\n",
       " 'milk': 7,\n",
       " 'moved': 28,\n",
       " 'no': 6,\n",
       " 'office': 24,\n",
       " 'picked': 1,\n",
       " 'put': 33,\n",
       " 'sandra': 2,\n",
       " 'the': 32,\n",
       " 'there': 16,\n",
       " 'to': 14,\n",
       " 'took': 9,\n",
       " 'travelled': 20,\n",
       " 'up': 17,\n",
       " 'went': 26,\n",
       " 'yes': 19}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []\n",
    "\n",
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_story_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functionalize Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_stories(data, word_index=tokenizer.word_index, max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    '''\n",
    "    INPUT: \n",
    "    \n",
    "    data: consisting of Stories,Queries,and Answers\n",
    "    word_index: word index dictionary from tokenizer\n",
    "    max_story_len: the length of the longest story (used for pad_sequences function)\n",
    "    max_question_len: length of the longest question (used for pad_sequences function)\n",
    "\n",
    "\n",
    "    OUTPUT:\n",
    "    \n",
    "    Vectorizes the stories,questions, and answers into padded sequences. We first loop for every story, query , and\n",
    "    answer in the data. Then we convert the raw words to an word index value. Then we append each set to their appropriate\n",
    "    output list. Then once we have converted the words to numbers, we pad the sequences so they are all of equal length.\n",
    "    \n",
    "    Returns this in the form of a tuple (X,Xq,Y) (padded based on max lengths)\n",
    "    '''\n",
    "    \n",
    "    \n",
    "    # X = STORIES\n",
    "    X = []\n",
    "    # Xq = QUERY/QUESTION\n",
    "    Xq = []\n",
    "    # Y = CORRECT ANSWER\n",
    "    Y = []\n",
    "    \n",
    "    \n",
    "    for story, query, answer in data:\n",
    "        \n",
    "        # Grab the word index for every word in story\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        # Grab the word index for every word in query\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        # Grab the Answers (either Yes/No so we don't need to use list comprehension here)\n",
    "        # Index 0 is reserved so we're going to use + 1\n",
    "        y = np.zeros(len(word_index) + 1)\n",
    "        \n",
    "        # Now that y is all zeros and we know its just Yes/No , we can use numpy logic to create this assignment\n",
    "        #\n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        # Append each set of story,query, and answer to their respective holding lists\n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    # Finally, pad the sequences based on their max length so the RNN can be trained on uniformly long sequences.\n",
    "        \n",
    "    # RETURN TUPLE FOR UNPACKING\n",
    "    return (pad_sequences(X, maxlen=max_story_len),pad_sequences(Xq, maxlen=max_question_len), np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 18,  1, 12],\n",
       "       [ 0,  0,  0, ..., 18,  8, 12],\n",
       "       [ 0,  0,  0, ..., 18,  8, 12],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 18, 23, 12],\n",
       "       [ 0,  0,  0, ..., 18,  8, 12],\n",
       "       [ 0,  0,  0, ..., 23, 34, 12]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  3, 32, 18, 33, 22],\n",
       "       [ 4,  3, 32, 18, 33, 22],\n",
       "       [ 4,  3, 32, 18,  8, 22],\n",
       "       ...,\n",
       "       [ 4, 10, 32, 18,  1, 22],\n",
       "       [ 4, 28, 32, 18,  8, 22],\n",
       "       [ 4, 10, 32, 18,  8, 22]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0.,   0.,   0.,   0., 503.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0., 497.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.layers import Input, Activation, Dense, Permute, Dropout\n",
    "from tensorflow.keras.layers import add, dot, concatenate\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Placeholders for Inputs\n",
    "\n",
    "Recall we technically have two inputs, stories and questions. So we need to use placeholders. `Input()` is used to instantiate a Keras tensor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Building the Networks\n",
    "\n",
    "To understand why we chose this setup, make sure to read the paper we are using:\n",
    "\n",
    "* Sainbayar Sukhbaatar, Arthur Szlam, Jason Weston, Rob Fergus,\n",
    "  \"End-To-End Memory Networks\",\n",
    "  http://arxiv.org/abs/1503.08895"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoders\n",
    "\n",
    "### Input Encoder m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input gets embedded to a sequence of vectors\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.3))\n",
    "\n",
    "# This encoder will output:\n",
    "# (samples, story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Encoder c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the input into a sequence of vectors of size query_maxlen\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.3))\n",
    "# output: (samples, story_maxlen, query_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed the question into a sequence of vectors\n",
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,\n",
    "                               output_dim=64,\n",
    "                               input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.3))\n",
    "# output: (samples, query_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode the Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode input sequence and questions (which are indices)\n",
    "# to sequences of dense vectors\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use dot product to compute the match between first input vector seq and the query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape: `(samples, story_maxlen, query_maxlen)`\n",
    "match = dot([input_encoded_m, question_encoded], axes=(2, 2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add this match matrix with the second input vector sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the match matrix with the second input vector sequence\n",
    "response = add([match, input_encoded_c])  # (samples, story_maxlen, query_maxlen)\n",
    "response = Permute((2, 1))(response)  # (samples, query_maxlen, story_maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the match matrix with the question vector sequence\n",
    "answer = concatenate([response, question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 6, 220) dtype=float32 (created by layer 'concatenate')>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce with RNN (LSTM)\n",
    "answer = LSTM(32)(answer)  # (samples, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization with Dropout\n",
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer)  # (samples, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we output a probability distribution over the vocabulary\n",
    "answer = Activation('softmax')(answer)\n",
    "\n",
    "# build the final model\n",
    "model = Model([input_sequence, question], answer)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 156)]        0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 6)]          0           []                               \n",
      "                                                                                                  \n",
      " sequential_1 (Sequential)      (None, None, 64)     2432        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " sequential_3 (Sequential)      (None, 6, 64)        2432        ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " dot (Dot)                      (None, 156, 6)       0           ['sequential_1[0][0]',           \n",
      "                                                                  'sequential_3[0][0]']           \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 156, 6)       0           ['dot[0][0]']                    \n",
      "                                                                                                  \n",
      " sequential_2 (Sequential)      (None, None, 6)      228         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 156, 6)       0           ['activation[0][0]',             \n",
      "                                                                  'sequential_2[0][0]']           \n",
      "                                                                                                  \n",
      " permute (Permute)              (None, 6, 156)       0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 6, 220)       0           ['permute[0][0]',                \n",
      "                                                                  'sequential_3[0][0]']           \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 32)           32384       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 32)           0           ['lstm[0][0]']                   \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 38)           1254        ['dropout_4[0][0]']              \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 38)           0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "313/313 [==============================] - 12s 21ms/step - loss: 0.9045 - accuracy: 0.4970 - val_loss: 0.6946 - val_accuracy: 0.5030\n",
      "Epoch 2/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.7043 - accuracy: 0.4996 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
      "Epoch 3/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.6958 - accuracy: 0.4941 - val_loss: 0.6991 - val_accuracy: 0.5030\n",
      "Epoch 4/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.6949 - accuracy: 0.5032 - val_loss: 0.6939 - val_accuracy: 0.5030\n",
      "Epoch 5/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.6945 - accuracy: 0.5038 - val_loss: 0.7026 - val_accuracy: 0.5030\n",
      "Epoch 6/120\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.6945 - accuracy: 0.5028 - val_loss: 0.6945 - val_accuracy: 0.4970\n",
      "Epoch 7/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.6940 - accuracy: 0.5053 - val_loss: 0.6933 - val_accuracy: 0.5030\n",
      "Epoch 8/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.6943 - accuracy: 0.5069 - val_loss: 0.6953 - val_accuracy: 0.5030\n",
      "Epoch 9/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.6947 - accuracy: 0.4969 - val_loss: 0.6935 - val_accuracy: 0.5030\n",
      "Epoch 10/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.6945 - accuracy: 0.4952 - val_loss: 0.6957 - val_accuracy: 0.4970\n",
      "Epoch 11/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.6929 - accuracy: 0.5150 - val_loss: 0.6955 - val_accuracy: 0.4790\n",
      "Epoch 12/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.6884 - accuracy: 0.5273 - val_loss: 0.6888 - val_accuracy: 0.5400\n",
      "Epoch 13/120\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.6719 - accuracy: 0.5619 - val_loss: 0.6761 - val_accuracy: 0.5520\n",
      "Epoch 14/120\n",
      "313/313 [==============================] - 8s 25ms/step - loss: 0.6497 - accuracy: 0.6065 - val_loss: 0.6416 - val_accuracy: 0.6660\n",
      "Epoch 15/120\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.6282 - accuracy: 0.6498 - val_loss: 0.6315 - val_accuracy: 0.6650\n",
      "Epoch 16/120\n",
      "313/313 [==============================] - 8s 24ms/step - loss: 0.6160 - accuracy: 0.6650 - val_loss: 0.6346 - val_accuracy: 0.6400\n",
      "Epoch 17/120\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.6080 - accuracy: 0.6711 - val_loss: 0.6099 - val_accuracy: 0.6720\n",
      "Epoch 18/120\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.5965 - accuracy: 0.6875 - val_loss: 0.6042 - val_accuracy: 0.6800\n",
      "Epoch 19/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.5900 - accuracy: 0.6895 - val_loss: 0.5943 - val_accuracy: 0.6770\n",
      "Epoch 20/120\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.5801 - accuracy: 0.6985 - val_loss: 0.5792 - val_accuracy: 0.7040\n",
      "Epoch 21/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.5659 - accuracy: 0.7129 - val_loss: 0.5661 - val_accuracy: 0.6940\n",
      "Epoch 22/120\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.5434 - accuracy: 0.7342 - val_loss: 0.5119 - val_accuracy: 0.7500\n",
      "Epoch 23/120\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.5166 - accuracy: 0.7553 - val_loss: 0.4772 - val_accuracy: 0.7830\n",
      "Epoch 24/120\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.4910 - accuracy: 0.7735 - val_loss: 0.4591 - val_accuracy: 0.7820\n",
      "Epoch 25/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.4742 - accuracy: 0.7826 - val_loss: 0.4398 - val_accuracy: 0.7930\n",
      "Epoch 26/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.4526 - accuracy: 0.7946 - val_loss: 0.4306 - val_accuracy: 0.7990\n",
      "Epoch 27/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.4390 - accuracy: 0.8021 - val_loss: 0.4145 - val_accuracy: 0.8000\n",
      "Epoch 28/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.4318 - accuracy: 0.8058 - val_loss: 0.4034 - val_accuracy: 0.8100\n",
      "Epoch 29/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.4273 - accuracy: 0.8027 - val_loss: 0.4092 - val_accuracy: 0.8060\n",
      "Epoch 30/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.4156 - accuracy: 0.8154 - val_loss: 0.4151 - val_accuracy: 0.8030\n",
      "Epoch 31/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.4158 - accuracy: 0.8068 - val_loss: 0.3914 - val_accuracy: 0.8130\n",
      "Epoch 32/120\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.4088 - accuracy: 0.8107 - val_loss: 0.3888 - val_accuracy: 0.8130\n",
      "Epoch 33/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.4013 - accuracy: 0.8137 - val_loss: 0.3911 - val_accuracy: 0.8120\n",
      "Epoch 34/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3925 - accuracy: 0.8176 - val_loss: 0.3886 - val_accuracy: 0.8160\n",
      "Epoch 35/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3929 - accuracy: 0.8194 - val_loss: 0.3981 - val_accuracy: 0.8090\n",
      "Epoch 36/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3760 - accuracy: 0.8285 - val_loss: 0.3846 - val_accuracy: 0.8240\n",
      "Epoch 37/120\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.3740 - accuracy: 0.8311 - val_loss: 0.3728 - val_accuracy: 0.8220\n",
      "Epoch 38/120\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.3722 - accuracy: 0.8288 - val_loss: 0.3896 - val_accuracy: 0.8260\n",
      "Epoch 39/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3650 - accuracy: 0.8316 - val_loss: 0.4244 - val_accuracy: 0.8040\n",
      "Epoch 40/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3619 - accuracy: 0.8365 - val_loss: 0.3586 - val_accuracy: 0.8360\n",
      "Epoch 41/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3548 - accuracy: 0.8365 - val_loss: 0.3614 - val_accuracy: 0.8300\n",
      "Epoch 42/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3533 - accuracy: 0.8376 - val_loss: 0.3775 - val_accuracy: 0.8320\n",
      "Epoch 43/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.3506 - accuracy: 0.8390 - val_loss: 0.3834 - val_accuracy: 0.8290\n",
      "Epoch 44/120\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.3491 - accuracy: 0.8384 - val_loss: 0.3792 - val_accuracy: 0.8230\n",
      "Epoch 45/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3466 - accuracy: 0.8418 - val_loss: 0.3675 - val_accuracy: 0.8330\n",
      "Epoch 46/120\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.3476 - accuracy: 0.8422 - val_loss: 0.3685 - val_accuracy: 0.8160\n",
      "Epoch 47/120\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.3451 - accuracy: 0.8445 - val_loss: 0.3919 - val_accuracy: 0.8120\n",
      "Epoch 48/120\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.3341 - accuracy: 0.8485 - val_loss: 0.3828 - val_accuracy: 0.8120\n",
      "Epoch 49/120\n",
      "313/313 [==============================] - 6s 21ms/step - loss: 0.3386 - accuracy: 0.8460 - val_loss: 0.3599 - val_accuracy: 0.8300\n",
      "Epoch 50/120\n",
      "313/313 [==============================] - 6s 21ms/step - loss: 0.3312 - accuracy: 0.8452 - val_loss: 0.3777 - val_accuracy: 0.8120\n",
      "Epoch 51/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.3340 - accuracy: 0.8473 - val_loss: 0.3630 - val_accuracy: 0.8330\n",
      "Epoch 52/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.3302 - accuracy: 0.8510 - val_loss: 0.3673 - val_accuracy: 0.8250\n",
      "Epoch 53/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.3250 - accuracy: 0.8520 - val_loss: 0.3719 - val_accuracy: 0.8320\n",
      "Epoch 54/120\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.3267 - accuracy: 0.8501 - val_loss: 0.3592 - val_accuracy: 0.8280\n",
      "Epoch 55/120\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.3266 - accuracy: 0.8517 - val_loss: 0.3741 - val_accuracy: 0.8210\n",
      "Epoch 56/120\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.3238 - accuracy: 0.8517 - val_loss: 0.3908 - val_accuracy: 0.8310\n",
      "Epoch 57/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.3220 - accuracy: 0.8557 - val_loss: 0.3722 - val_accuracy: 0.8270\n",
      "Epoch 58/120\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.3172 - accuracy: 0.8572 - val_loss: 0.3582 - val_accuracy: 0.8250\n",
      "Epoch 59/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3160 - accuracy: 0.8568 - val_loss: 0.3750 - val_accuracy: 0.8310\n",
      "Epoch 60/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.3197 - accuracy: 0.8560 - val_loss: 0.3587 - val_accuracy: 0.8300\n",
      "Epoch 61/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3136 - accuracy: 0.8599 - val_loss: 0.3751 - val_accuracy: 0.8280\n",
      "Epoch 62/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3082 - accuracy: 0.8608 - val_loss: 0.3746 - val_accuracy: 0.8310\n",
      "Epoch 63/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3103 - accuracy: 0.8604 - val_loss: 0.3749 - val_accuracy: 0.8330\n",
      "Epoch 64/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3150 - accuracy: 0.8593 - val_loss: 0.3726 - val_accuracy: 0.8280\n",
      "Epoch 65/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3089 - accuracy: 0.8610 - val_loss: 0.3656 - val_accuracy: 0.8250\n",
      "Epoch 66/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3067 - accuracy: 0.8636 - val_loss: 0.3682 - val_accuracy: 0.8300\n",
      "Epoch 67/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.3019 - accuracy: 0.8643 - val_loss: 0.3683 - val_accuracy: 0.8280\n",
      "Epoch 68/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.2997 - accuracy: 0.8663 - val_loss: 0.3885 - val_accuracy: 0.8270\n",
      "Epoch 69/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2978 - accuracy: 0.8670 - val_loss: 0.3646 - val_accuracy: 0.8280\n",
      "Epoch 70/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.3028 - accuracy: 0.8639 - val_loss: 0.4187 - val_accuracy: 0.8180\n",
      "Epoch 71/120\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2962 - accuracy: 0.8690 - val_loss: 0.3701 - val_accuracy: 0.8210\n",
      "Epoch 72/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2877 - accuracy: 0.8683 - val_loss: 0.3875 - val_accuracy: 0.8330\n",
      "Epoch 73/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2901 - accuracy: 0.8718 - val_loss: 0.3926 - val_accuracy: 0.8250\n",
      "Epoch 74/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2877 - accuracy: 0.8712 - val_loss: 0.3832 - val_accuracy: 0.8260\n",
      "Epoch 75/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.2889 - accuracy: 0.8711 - val_loss: 0.3964 - val_accuracy: 0.8310\n",
      "Epoch 76/120\n",
      "313/313 [==============================] - 5s 18ms/step - loss: 0.2866 - accuracy: 0.8749 - val_loss: 0.3797 - val_accuracy: 0.8270\n",
      "Epoch 77/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.2893 - accuracy: 0.8711 - val_loss: 0.4012 - val_accuracy: 0.8230\n",
      "Epoch 78/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.2776 - accuracy: 0.8787 - val_loss: 0.4090 - val_accuracy: 0.8330\n",
      "Epoch 79/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.2845 - accuracy: 0.8770 - val_loss: 0.3729 - val_accuracy: 0.8250\n",
      "Epoch 80/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2841 - accuracy: 0.8788 - val_loss: 0.3893 - val_accuracy: 0.8270\n",
      "Epoch 81/120\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2752 - accuracy: 0.8797 - val_loss: 0.4055 - val_accuracy: 0.8310\n",
      "Epoch 82/120\n",
      "313/313 [==============================] - 8s 26ms/step - loss: 0.2794 - accuracy: 0.8765 - val_loss: 0.4302 - val_accuracy: 0.8180\n",
      "Epoch 83/120\n",
      "313/313 [==============================] - 10s 33ms/step - loss: 0.2771 - accuracy: 0.8793 - val_loss: 0.4334 - val_accuracy: 0.8190\n",
      "Epoch 84/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.2667 - accuracy: 0.8823 - val_loss: 0.3853 - val_accuracy: 0.8270\n",
      "Epoch 85/120\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.2765 - accuracy: 0.8793 - val_loss: 0.3971 - val_accuracy: 0.8240\n",
      "Epoch 86/120\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2775 - accuracy: 0.8787 - val_loss: 0.3969 - val_accuracy: 0.8280\n",
      "Epoch 87/120\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.2683 - accuracy: 0.8812 - val_loss: 0.4360 - val_accuracy: 0.8210\n",
      "Epoch 88/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.2686 - accuracy: 0.8843 - val_loss: 0.4103 - val_accuracy: 0.8260\n",
      "Epoch 89/120\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.2647 - accuracy: 0.8819 - val_loss: 0.4041 - val_accuracy: 0.8270\n",
      "Epoch 90/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.2556 - accuracy: 0.8872 - val_loss: 0.4191 - val_accuracy: 0.8320\n",
      "Epoch 91/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.2640 - accuracy: 0.8880 - val_loss: 0.4194 - val_accuracy: 0.8270\n",
      "Epoch 92/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2618 - accuracy: 0.8883 - val_loss: 0.4034 - val_accuracy: 0.8290\n",
      "Epoch 93/120\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.2596 - accuracy: 0.8875 - val_loss: 0.4033 - val_accuracy: 0.8250\n",
      "Epoch 94/120\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2581 - accuracy: 0.8890 - val_loss: 0.4022 - val_accuracy: 0.8430\n",
      "Epoch 95/120\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2638 - accuracy: 0.8862 - val_loss: 0.3861 - val_accuracy: 0.8410\n",
      "Epoch 96/120\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2553 - accuracy: 0.8871 - val_loss: 0.3957 - val_accuracy: 0.8320\n",
      "Epoch 97/120\n",
      "313/313 [==============================] - 6s 21ms/step - loss: 0.2548 - accuracy: 0.8895 - val_loss: 0.4109 - val_accuracy: 0.8310\n",
      "Epoch 98/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.2532 - accuracy: 0.8944 - val_loss: 0.4153 - val_accuracy: 0.8320\n",
      "Epoch 99/120\n",
      "313/313 [==============================] - 7s 24ms/step - loss: 0.2535 - accuracy: 0.8903 - val_loss: 0.4119 - val_accuracy: 0.8270\n",
      "Epoch 100/120\n",
      "313/313 [==============================] - 7s 21ms/step - loss: 0.2558 - accuracy: 0.8887 - val_loss: 0.3841 - val_accuracy: 0.8330\n",
      "Epoch 101/120\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.2431 - accuracy: 0.8951 - val_loss: 0.4473 - val_accuracy: 0.8230\n",
      "Epoch 102/120\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.2456 - accuracy: 0.8928 - val_loss: 0.3956 - val_accuracy: 0.8410\n",
      "Epoch 103/120\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2460 - accuracy: 0.8926 - val_loss: 0.4220 - val_accuracy: 0.8380\n",
      "Epoch 104/120\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.2466 - accuracy: 0.8923 - val_loss: 0.4107 - val_accuracy: 0.8400\n",
      "Epoch 105/120\n",
      "313/313 [==============================] - 7s 22ms/step - loss: 0.2509 - accuracy: 0.8923 - val_loss: 0.4153 - val_accuracy: 0.8330\n",
      "Epoch 106/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2440 - accuracy: 0.8960 - val_loss: 0.4003 - val_accuracy: 0.8350\n",
      "Epoch 107/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2415 - accuracy: 0.8943 - val_loss: 0.4141 - val_accuracy: 0.8370\n",
      "Epoch 108/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2501 - accuracy: 0.8917 - val_loss: 0.4189 - val_accuracy: 0.8330\n",
      "Epoch 109/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2412 - accuracy: 0.8973 - val_loss: 0.4283 - val_accuracy: 0.8310\n",
      "Epoch 110/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2441 - accuracy: 0.8956 - val_loss: 0.4214 - val_accuracy: 0.8390\n",
      "Epoch 111/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.2351 - accuracy: 0.8985 - val_loss: 0.4521 - val_accuracy: 0.8320\n",
      "Epoch 112/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2341 - accuracy: 0.8987 - val_loss: 0.4483 - val_accuracy: 0.8380\n",
      "Epoch 113/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2383 - accuracy: 0.8970 - val_loss: 0.4186 - val_accuracy: 0.8390\n",
      "Epoch 114/120\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2390 - accuracy: 0.8987 - val_loss: 0.4341 - val_accuracy: 0.8370\n",
      "Epoch 115/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2330 - accuracy: 0.9020 - val_loss: 0.4502 - val_accuracy: 0.8370\n",
      "Epoch 116/120\n",
      "313/313 [==============================] - 5s 17ms/step - loss: 0.2373 - accuracy: 0.8991 - val_loss: 0.4400 - val_accuracy: 0.8320\n",
      "Epoch 117/120\n",
      "313/313 [==============================] - 6s 18ms/step - loss: 0.2302 - accuracy: 0.9002 - val_loss: 0.4429 - val_accuracy: 0.8380\n",
      "Epoch 118/120\n",
      "313/313 [==============================] - 6s 20ms/step - loss: 0.2318 - accuracy: 0.9053 - val_loss: 0.4658 - val_accuracy: 0.8310\n",
      "Epoch 119/120\n",
      "313/313 [==============================] - 7s 23ms/step - loss: 0.2339 - accuracy: 0.9008 - val_loss: 0.4183 - val_accuracy: 0.8370\n",
      "Epoch 120/120\n",
      "313/313 [==============================] - 6s 19ms/step - loss: 0.2292 - accuracy: 0.9048 - val_loss: 0.4315 - val_accuracy: 0.8330\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "history = model.fit([inputs_train, queries_train], answers_train,batch_size=32,epochs=120,validation_data=([inputs_test, queries_test], answers_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'chatbot_120_epochs_my.h5'\n",
    "model.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "\n",
    "### Plotting Out Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on Given Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(filename)\n",
    "pred_results = model.predict(([inputs_test, queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mary',\n",
       " 'got',\n",
       " 'the',\n",
       " 'milk',\n",
       " 'there',\n",
       " '.',\n",
       " 'John',\n",
       " 'moved',\n",
       " 'to',\n",
       " 'the',\n",
       " 'bedroom',\n",
       " '.']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary got the milk there . John moved to the bedroom .\n"
     ]
    }
   ],
   "source": [
    "story =' '.join(word for word in test_data[0][0])\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is John in the kitchen ?\n"
     ]
    }
   ],
   "source": [
    "query = ' '.join(word for word in test_data[0][1])\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Test Answer from Data is: no\n"
     ]
    }
   ],
   "source": [
    "print(\"True Test Answer from Data is:\",test_data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  no\n",
      "Probability of certainty was:  0.999997\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Your Own Stories and Questions\n",
    "\n",
    "Remember you can only use words from the existing vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the whitespace of the periods\n",
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden .\"\n",
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(),my_question.split(),'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story,my_ques,my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([ my_story, my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted answer is:  yes\n",
      "Probability of certainty was:  0.9654305\n"
     ]
    }
   ],
   "source": [
    "#Generate prediction from model\n",
    "val_max = np.argmax(pred_results[0])\n",
    "\n",
    "for key, val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key\n",
    "\n",
    "print(\"Predicted answer is: \", k)\n",
    "print(\"Probability of certainty was: \", pred_results[0][val_max])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
